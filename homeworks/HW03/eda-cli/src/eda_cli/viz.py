import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Any, List
import numpy as np

def save_histograms(
    df: pd.DataFrame, 
    out_dir: Path, 
    max_columns: int = 5
) -> List[str]:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫.
    
    Args:
        max_columns: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è
    """
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    saved_images = []
    
    cols_to_plot = numeric_cols[:max_columns]
    
    for i, col in enumerate(cols_to_plot):
        plt.figure(figsize=(10, 6))
        
        data = df[col].dropna()
        
        if len(data) > 0:
            plt.hist(data, bins=min(30, len(data)//10 + 1), edgecolor='black', alpha=0.7)
            plt.title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {col}')
            plt.xlabel(col)
            plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
            
            stats_text = f'n={len(data)}\nmean={data.mean():.2f}\nstd={data.std():.2f}'
            plt.text(0.7, 0.7, stats_text, transform=plt.gca().transAxes,
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
            
            filename = out_dir / f'hist_{col.replace(" ", "_")}.png'
            plt.tight_layout()
            plt.savefig(filename, dpi=100)
            plt.close()
            
            saved_images.append(filename.name)
        else:
            plt.close()
    
    if len(numeric_cols) > max_columns:
        print(f"‚ö†Ô∏è –ü–æ—Å—Ç—Ä–æ–µ–Ω–æ —Ç–æ–ª—å–∫–æ {max_columns} –∏–∑ {len(numeric_cols)} —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫.")
        print(f"   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --max-hist-columns –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞.")
    
    return saved_images

def create_report(
    df: pd.DataFrame,
    quality_flags: Dict[str, Any],
    out_dir: Path,
    title: str = "EDA Report",
    max_hist_columns: int = 5,
    top_k_categories: int = 10,
    min_missing_share: float = 0.3,
    high_cardinality_threshold: int = 50
) -> None:
    """
    –°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
    """
    report_lines = []
    
    report_lines.append(f"# {title}")
    report_lines.append(f"*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Å –ø–æ–º–æ—â—å—é eda-cli*\n")
    
    report_lines.append("## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞")
    report_lines.append(f"- **–ú–∞–∫—Å. –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º:** {max_hist_columns}")
    report_lines.append(f"- **–¢–æ–ø-K –∫–∞—Ç–µ–≥–æ—Ä–∏–π:** {top_k_categories}")
    report_lines.append(f"- **–ü–æ—Ä–æ–≥ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤:** {min_missing_share:.0%}")
    report_lines.append(f"- **–ü–æ—Ä–æ–≥ –≤—ã—Å–æ–∫–æ–π –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:** {high_cardinality_threshold}")
    report_lines.append("")
    report_lines.append("## üìä –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    report_lines.append(f"- **–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:** {quality_flags['n_rows']} —Å—Ç—Ä–æ–∫ √ó {quality_flags['n_cols']} –∫–æ–ª–æ–Ω–æ–∫")
    report_lines.append(f"- **–ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏:** {quality_flags.get('numeric_columns_count', 0)}")
    report_lines.append(f"- **–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:** {quality_flags.get('categorical_columns_count', 0)}")
    report_lines.append(f"- **–ö–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏:** {quality_flags.get('date_columns_count', 0)}")
    report_lines.append("")
    

    report_lines.append("## üîç –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö")
    report_lines.append(f"- **–ò–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω—ã–π score:** `{quality_flags['quality_score']:.2f}/1.00`")
    
    missing_info = []
    if quality_flags['problematic_missing_cols']:
        for item in quality_flags['problematic_missing_cols'][:10]:
            missing_info.append(f"  - `{item['column']}`: {item['missing_ratio']:.1%}")
    
    if missing_info:
        report_lines.append(f"- **‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∏ —Å >{min_missing_share:.0%} –ø—Ä–æ–ø—É—Å–∫–æ–≤:**")
        report_lines.extend(missing_info)
        if len(quality_flags['problematic_missing_cols']) > 10:
            report_lines.append(f"  *... –∏ –µ—â–µ {len(quality_flags['problematic_missing_cols']) - 10} –∫–æ–ª–æ–Ω–æ–∫*")
    else:
        report_lines.append(f"- **‚úì –ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ —Å >{min_missing_share:.0%} –ø—Ä–æ–ø—É—Å–∫–æ–≤**")
    report_lines.append("")
    
    if quality_flags['has_duplicates']:
        report_lines.append(f"- **‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–∫:** {quality_flags['duplicate_rows']}")
    else:
        report_lines.append("- **‚úì –ù–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å—Ç—Ä–æ–∫**")
    report_lines.append("")
    
    if quality_flags['has_constant_columns']:
        report_lines.append(f"- **‚ö†Ô∏è –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**")
        for col in quality_flags['constant_columns_list']:
            report_lines.append(f"  - `{col}`")
    else:
        report_lines.append("- **‚úì –ù–µ—Ç –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫**")
    report_lines.append("")
    
    if quality_flags['has_high_cardinality_categoricals']:
        report_lines.append(f"- **‚ö†Ô∏è –í—ã—Å–æ–∫–∞—è –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å (> {high_cardinality_threshold} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π):**")
        for col, count in quality_flags['high_cardinality_columns'].items():
            report_lines.append(f"  - `{col}`: {count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
    else:
        report_lines.append("- **‚úì –ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é**")
    report_lines.append("")
    
    if quality_flags['has_suspicious_id_duplicates']:
        report_lines.append("- **‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å—é ID:**")
        for col, count in quality_flags['suspicious_id_duplicates'].items():
            report_lines.append(f"  - `{col}`: {count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    report_lines.append("")
    
    report_lines.append(f"## üìà –¢–æ–ø-{top_k_categories} –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º")
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    
    if len(categorical_cols) > 0:
        for col in categorical_cols[:10]:
            value_counts = df[col].value_counts()
            total = len(df[col].dropna())
            
            if total > 0:
                report_lines.append(f"### `{col}`")
                report_lines.append(f"–í—Å–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–π: {total} | –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {value_counts.shape[0]}")
                
                top_values = value_counts.head(top_k_categories)
                for value, count in top_values.items():
                    percentage = count / total * 100
                    report_lines.append(f"- `{value}`: {count} ({percentage:.1f}%)")
                
                if len(value_counts) > top_k_categories:
                    other_count = value_counts.iloc[top_k_categories:].sum()
                    other_pct = other_count / total * 100
                    report_lines.append(f"- *... –∏ –µ—â–µ {len(value_counts) - top_k_categories} –∑–Ω–∞—á–µ–Ω–∏–π: {other_count} ({other_pct:.1f}%)*")
                
                report_lines.append("")
    else:
        report_lines.append("–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.\n")
    
    report_lines.append(f"## üìä –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    report_lines.append(f"*–ü–æ—Å—Ç—Ä–æ–µ–Ω–æ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º: {max_hist_columns} –∏–∑ {quality_flags.get('numeric_columns_count', 0)} —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫*")
    
    saved_images = save_histograms(df, out_dir, max_columns=max_hist_columns)
    
    if saved_images:
        for img in saved_images:
            report_lines.append(f"![{img}]({img})")
        report_lines.append("")
    else:
        report_lines.append("–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.\n")
    
    numeric_cols = df.select_dtypes(include=['number']).columns
    if len(numeric_cols) > 0:
        report_lines.append("## üìê –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∏—Å–ª–æ–≤—ã–º –∫–æ–ª–æ–Ω–∫–∞–º")
        report_lines.append("| –ö–æ–ª–æ–Ω–∫–∞ | –°—Ä–µ–¥–Ω–µ–µ | –ú–µ–¥–∏–∞–Ω–∞ | Std | Min | Max |")
        report_lines.append("|---------|---------|---------|-----|-----|-----|")
        
        for col in numeric_cols[:15]:
            stats = df[col].describe()
            report_lines.append(
                f"| `{col}` | {stats.get('mean', 'NA'):.2f} | {stats.get('50%', 'NA'):.2f} | "
                f"{stats.get('std', 'NA'):.2f} | {stats.get('min', 'NA'):.2f} | {stats.get('max', 'NA'):.2f} |"
            )
        
        if len(numeric_cols) > 15:
            report_lines.append(f"| *... –∏ –µ—â–µ {len(numeric_cols) - 15} –∫–æ–ª–æ–Ω–æ–∫* |")
        report_lines.append("")

    report_lines.append("## üéØ –í—ã–≤–æ–¥—ã")
    score = quality_flags['quality_score']
    
    if score > 0.8:
        report_lines.append("‚úÖ **–û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö.** –ú–æ–∂–Ω–æ —Å—Ä–∞–∑—É –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –∫ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é.")
    elif score > 0.6:
        report_lines.append("‚ö†Ô∏è **–°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö.** –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö.")
    elif score > 0.4:
        report_lines.append("‚ö†Ô∏è **–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö.** –¢—Ä–µ–±—É–µ—Ç—Å—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞.")
    else:
        report_lines.append("‚ùå **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö.** –í–æ–∑–º–æ–∂–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–∏—Å–∫ –Ω–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞.")
    
    report_lines.append("")
    report_lines.append("---")
    report_lines.append(f"*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: max_hist_columns={max_hist_columns}, "
                       f"top_k_categories={top_k_categories}, min_missing_share={min_missing_share:.0%}*")
    
    report_path = out_dir / "report.md"
    report_path.write_text("\n".join(report_lines), encoding="utf-8")
    
    import json
    summary = {
        "title": title,
        "parameters": {
            "max_hist_columns": max_hist_columns,
            "top_k_categories": top_k_categories,
            "min_missing_share": min_missing_share,
            "high_cardinality_threshold": high_cardinality_threshold
        },
        "basic_metrics": {
            "n_rows": quality_flags['n_rows'],
            "n_cols": quality_flags['n_cols'],
            "quality_score": quality_flags['quality_score']
        },
        "problematic_columns": {
            "high_missing": [item['column'] for item in quality_flags['problematic_missing_cols']],
            "constant": quality_flags['constant_columns_list'],
            "high_cardinality": list(quality_flags['high_cardinality_columns'].keys())
        }
    }
    
    json_path = out_dir / "summary.json"
    json_path.write_text(json.dumps(summary, indent=2, ensure_ascii=False), encoding="utf-8")