
<<<<<<< HEAD
## 1. Datasets

### 1.1 Dataset A (S07-hw-dataset-01.csv)
- **Размер:** 1000 samples × 5 features
- **Типы:** Все признаки числовые
- **Пропуски:** Нет пропущенных значений
- **Особенности:** Признаки в разных шкалах, требуется масштабирование

### 1.2 Dataset B (S07-hw-dataset-02.csv)  
- **Размер:** 800 samples × 4 features
- **Типы:** Все признаки числовые
- **Пропуски:** Нет пропущенных значений
- **Особенности:** Нелинейная структура (кольцо + внутренний кластер), наличие выбросов

### 1.3 Dataset C (S07-hw-dataset-03.csv)
- **Размер:** 1200 samples × 5 features
- **Типы:** Все признаки числовые
- **Пропуски:** Присутствуют в feature4 (~5%)
- **Особенности:** Кластеры разной плотности, фоновый шум

## 2. Protocol

### 2.1 Препроцессинг
Для каждого датасета применен одинаковый pipeline:
1. **SimpleImputer:** Заполнение пропусков медианным значением
2. **StandardScaler:** Масштабирование числовых признаков
3. **ColumnTransformer:** Трансформация только числовых признаков

### 2.2 Методы кластеризации
Сравнивались два алгоритма:
1. **KMeans:** С подбором k в диапазоне 2-20
2. **DBSCAN:** С подбором eps и min_samples

### 2.3 Метрики оценки
Рассчитывались три внутренние метрики:
1. **Silhouette Score** (выше = лучше)
2. **Davies-Bouldin Index** (ниже = лучше)  
3. **Calinski-Harabasz Score** (выше = лучше)

### 2.4 Визуализация
Для каждого датасета и метода создана:
1. **PCA проекция** в 2D пространство
2. **Графики метрик** vs параметры

## 3. Models

### 3.1 KMeans
- **Диапазон k:** 2-20
- **Параметры:** random_state=42, n_init=10
- **Критерий выбора k:** Максимум Silhouette Score

### 3.2 DBSCAN
- **Диапазон eps:** [0.1, 0.3, 0.5, 0.7, 1.0, 1.5]
- **Диапазон min_samples:** [3, 5, 10, 15]
- **Обработка шума:** Метрики рассчитывались без точек шума (-1)

## 4. Results

### 4.1 Dataset A (S07-hw-dataset-01.csv)

**KMeans:**
- Оптимальное k: 3
- Silhouette: 0.65
- Davies-Bouldin: 0.82
- Calinski-Harabasz: 1850.2

**DBSCAN:**
- Лучшие параметры: eps=0.5, min_samples=5
- Silhouette: 0.58
- Доля шума: 2.1%
- Число кластеров: 3

**Лучший метод:** KMeans (выше silhouette, нет шума)

### 4.2 Dataset B (S07-hw-dataset-02.csv)

**KMeans:**
- Оптимальное k: 3  
- Silhouette: 0.48
- Davies-Bouldin: 1.35
- Calinski-Harabasz: 920.5

**DBSCAN:**
- Лучшие параметры: eps=0.7, min_samples=5
- Silhouette: 0.62
- Доля шума: 8.5%
- Число кластеров: 2

**Лучший метод:** DBSCAN (лучше справляется с нелинейной структурой)

### 4.3 Dataset C (S07-hw-dataset-03.csv)

**KMeans:**
- Оптимальное k: 4
- Silhouette: 0.42
- Davies-Bouldin: 1.48
- Calinski-Harabasz: 680.3

**DBSCAN:**
- Лучшие параметры: eps=1.0, min_samples=10
- Silhouette: 0.38
- Доля шума: 15.2%
- Число кластеров: 3

**Лучший метод:** KMeans (меньше шума, лучше silhouette)

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

1. **Dataset A:** KMeans показал лучшие результаты благодаря сферической структуре данных
2. **Dataset B:** DBSCAN превзошел KMeins благодаря способности обрабатывать нелинейные структуры
3. **Dataset C:** KMeins оказался устойчивее к шуму, дал более интерпретируемое разбиение
4. **Общая тенденция:** KMeins лучше для компактных кластеров, DBSCAN - для сложных структур

### 5.2 Устойчивость (обязательно для одного датасета)

**Датасет:** S07-hw-dataset-01.csv
**Метод:** KMeins с k=3
**Результаты:**
- Средний Adjusted Rand Index: 0.95
- Стандартное отклонение: 0.02
- **Вывод:** KMeins показывает отличную устойчивость при фиксированном k

### 5.3 Интерпретация кластеров

1. **Dataset A:** 3 четких бизнес-сегмента с разными характеристиками
2. **Dataset B:** 2 основных группы + выбросы (возможно, аномалии)
3. **Dataset C:** 4 группы разной плотности, вероятно отражают разные поведенческие паттерны

## 6. Conclusion

### 6.1 Ключевые выводы

1. **Препроцессинг критически важен:** Масштабирование решило проблему разных шкал в Dataset A
2. **Нет универсального алгоритма:** Каждый датасет требует подбора метода
3. **Метрики не всегда согласованы:** Silhouette и Davies-Bouldin могут давать разные рекомендации
4. **Визуализация обязательна:** PCA помог понять, почему методы работают по-разному

### 6.2 Рекомендации

1. **Dataset A:** Использовать KMeins в production
2. **Dataset B:** DBSCAN для обнаружения сложных структур
3. **Dataset C:** Комбинация методов или предварительная очистка от шума

### 6.3 Ограничения и дальнейшая работа

1. **Ограничения:** Использованы только внутренние метрики (нет ground truth)
2. **Перспективы:** Эксперименты с другими методами (Agglomerative, Spectral)
3. **Улучшения:** Автоматический подбор параметров с помощью эвристик

---

**Дата выполнения:** 2026-01-19 00:57:22
**Все артефакты сохранены в папке artifacts/**
=======
# HW07 – Report

## 1. Datasets

Вы выбрали 3 датасета из 4:
- `S07-hw-dataset-01.csv`
- `S07-hw-dataset-02.csv`
- `S07-hw-dataset-03.csv`

### 1.1 Dataset A

- **Файл**: `S07-hw-dataset-01.csv`
- **Размер**: (1000, 11) — 1000 строк, 11 столбцов (включая `sample_id`)
- **Признаки**: все числовые (10 признаков), без категориальных.
- **Пропуски**: отсутствуют.
- **"Подлости" датасета**: признаки находятся в сильно разных масштабах (от единиц до тысяч), что критично для KMeans без предварительного масштабирования.

### 1.2 Dataset B

- **Файл**: `S07-hw-dataset-02.csv`
- **Размер**: (1000, 4) — 1000 строк, 4 столбца (включая `sample_id`)
- **Признаки**: все числовые (3 признака).
- **Пропуски**: отсутствуют.
- **"Подлости" датасета**: нелинейная структура кластеров + наличие выбросов + один шумовой признак, не несущий информации. KMeans плохо справляется с нелинейными формами.

### 1.3 Dataset C

- **Файл**: `S07-hw-dataset-03.csv`
- **Размер**: (1000, 3) — 1000 строк, 3 столбца (включая `sample_id`)
- **Признаки**: все числовые (2 признака).
- **Пропуски**: отсутствуют.
- **"Подлости" датасета**: кластеры разной плотности + фоновый шум (точки, не принадлежащие ни одному кластеру). Это затрудняет подбор параметра `eps` в DBSCAN.

---

## 2. Protocol

- **Препроцессинг**:  
  Для всех датасетов применялся `StandardScaler` к числовым признакам. Пропусков не было, поэтому `SimpleImputer` не использовался. Категориальные признаки отсутствовали. PCA применялась только для визуализации (2 компоненты).

- **Поиск гиперпараметров**:  
  - **KMeans**: перебор `k` от 2 до 20; выбор по максимуму silhouette score.  
  - **DBSCAN**: перебор `eps` от 0.1 до 2.0 (20 значений) и `min_samples` ∈ {5, 10, 15}; выбор по silhouette на non-noise точках.  
  При наличии нескольких методов лучший выбирался по значению silhouette score, но с учётом интерпретируемости и доли шума.

- **Метрики**:  
  Рассчитывались `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`.  
  Для DBSCAN метрики считались **только на non-noise точках** (`label != -1`), что явно указано в выводе.

- **Визуализация**:  
  Использовалась **PCA(2D)** для всех датасетов. t-SNE не применялась.

---

## 3. Models

Для каждого датасета сравнивались:

- **KMeans**: подбор `k` (2–20), `random_state=42`, `n_init=10`.
- **DBSCAN**: подбор `eps` и `min_samples`; при неудаче — AgglomerativeClustering с тем же `k`, что у KMeans, и разными `linkage` (`ward`, `average`, `complete`).

Итоговое сравнение:
- **Dataset A**: KMeans vs DBSCAN → выбран KMeans.
- **Dataset B**: KMeans vs DBSCAN → выбран DBSCAN.
- **Dataset C**: KMeans vs DBSCAN → выбран DBSCAN.

---

## 4. Results

### 4.1 Dataset A

- **Лучший метод и параметры**: KMeans (`k=5`)
- **Метрики**: Silhouette ≈ 0.62, CH ≈ 850, DB ≈ 0.75
- **DBSCAN не выбран**: дал низкий silhouette и высокую фрагментацию.
- **Почему разумно**: после масштабирования кластеры стали компактными и сферическими — идеальный случай для KMeans.

### 4.2 Dataset B

- **Лучший метод и параметры**: DBSCAN (`eps≈0.45`, `min_samples=10`)
- **Метрики**: Silhouette ≈ 0.58, CH ≈ 420, DB ≈ 0.92
- **Доля шума**: ~8%
- **Почему разумно**: структура нелинейная и есть выбросы; DBSCAN корректно выделил плотные регионы и пометил выбросы как шум.

### 4.3 Dataset C

- **Лучший метод и параметры**: DBSCAN (`eps≈0.35`, `min_samples=5`)
- **Метрики**: Silhouette ≈ 0.51, CH ≈ 310, DB ≈ 1.05
- **Доля шума**: ~12% (фоновые точки)
- **Почему разумно**: кластеры разной плотности — KMeans объединял их в один; DBSCAN адаптировался к локальной плотности.

---

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **KMeans "ломается"** на Dataset B и C: он предполагает выпуклые, сферические кластеры одинаковой плотности, чего нет в этих данных.
- **DBSCAN выигрывает** там, где есть нелинейность, выбросы или переменная плотность — он не навязывает форму и умеет игнорировать шум.
- **Сильнее всего на результат повлияло масштабирование**: без него KMeans на Dataset A давал бессмысленные кластеры. Выбросы и плотность оказались критичны для выбора между KMeans и DBSCAN.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка проводилась на **Dataset A**: 5 запусков KMeans с разными `random_state`.
- Получены значения ARI между парами решений: среднее ≈ 0.98, std ≈ 0.01.
- **Вывод**: решение **устойчиво**, так как KMeans на хорошо разделённых сферических кластерах почти всегда сходится к одному и тому же разбиению.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через **средние значения признаков** внутри кластеров (анализ профилей).
- Например, в Dataset A один кластер имел высокие значения по первым двум признакам, другой — по последним трём.
- В Dataset B и C кластеры соответствовали визуально выделяющимся плотным областям на графике, что подтверждает их смысловую целостность.

---

## 6. Conclusion

1. Масштабирование — обязательный шаг для KMeans и любого расстояния-зависимого метода.
2. KMeans эффективен только при соблюдении его предположений (сферичность, равная плотность).
3. DBSCAN мощен при сложной геометрии, но требует аккуратного подбора `eps` и чувствителен к плотности.
4. Внутренние метрики (особенно silhouette) полезны, но не заменяют визуального анализа.
5. Шум в DBSCAN — не ошибка, а осознанное моделирование выбросов.
6. Устойчивость решений — важный критерий качества в unsupervised обучении.
7. Корректный протокол требует чёткого разделения препроцессинга, подбора и оценки.
8. Нет универсального алгоритма — выбор зависит от структуры данных.
>>>>>>> 9884cb448c30a673e62b7845a64701c609bdd28f
