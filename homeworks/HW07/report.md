
# HW07 – Report

## 1. Datasets

Вы выбрали 3 датасета из 4:
- `S07-hw-dataset-01.csv`
- `S07-hw-dataset-02.csv`
- `S07-hw-dataset-03.csv`

### 1.1 Dataset A

- **Файл**: `S07-hw-dataset-01.csv`
- **Размер**: (1000, 11) — 1000 строк, 11 столбцов (включая `sample_id`)
- **Признаки**: все числовые (10 признаков), без категориальных.
- **Пропуски**: отсутствуют.
- **"Подлости" датасета**: признаки находятся в сильно разных масштабах (от единиц до тысяч), что критично для KMeans без предварительного масштабирования.

### 1.2 Dataset B

- **Файл**: `S07-hw-dataset-02.csv`
- **Размер**: (1000, 4) — 1000 строк, 4 столбца (включая `sample_id`)
- **Признаки**: все числовые (3 признака).
- **Пропуски**: отсутствуют.
- **"Подлости" датасета**: нелинейная структура кластеров + наличие выбросов + один шумовой признак, не несущий информации. KMeans плохо справляется с нелинейными формами.

### 1.3 Dataset C

- **Файл**: `S07-hw-dataset-03.csv`
- **Размер**: (1000, 3) — 1000 строк, 3 столбца (включая `sample_id`)
- **Признаки**: все числовые (2 признака).
- **Пропуски**: отсутствуют.
- **"Подлости" датасета**: кластеры разной плотности + фоновый шум (точки, не принадлежащие ни одному кластеру). Это затрудняет подбор параметра `eps` в DBSCAN.

---

## 2. Protocol

- **Препроцессинг**:  
  Для всех датасетов применялся `StandardScaler` к числовым признакам. Пропусков не было, поэтому `SimpleImputer` не использовался. Категориальные признаки отсутствовали. PCA применялась только для визуализации (2 компоненты).

- **Поиск гиперпараметров**:  
  - **KMeans**: перебор `k` от 2 до 20; выбор по максимуму silhouette score.  
  - **DBSCAN**: перебор `eps` от 0.1 до 2.0 (20 значений) и `min_samples` ∈ {5, 10, 15}; выбор по silhouette на non-noise точках.  
  При наличии нескольких методов лучший выбирался по значению silhouette score, но с учётом интерпретируемости и доли шума.

- **Метрики**:  
  Рассчитывались `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`.  
  Для DBSCAN метрики считались **только на non-noise точках** (`label != -1`), что явно указано в выводе.

- **Визуализация**:  
  Использовалась **PCA(2D)** для всех датасетов. t-SNE не применялась.

---

## 3. Models

Для каждого датасета сравнивались:

- **KMeans**: подбор `k` (2–20), `random_state=42`, `n_init=10`.
- **DBSCAN**: подбор `eps` и `min_samples`; при неудаче — AgglomerativeClustering с тем же `k`, что у KMeans, и разными `linkage` (`ward`, `average`, `complete`).

Итоговое сравнение:
- **Dataset A**: KMeans vs DBSCAN → выбран KMeans.
- **Dataset B**: KMeans vs DBSCAN → выбран DBSCAN.
- **Dataset C**: KMeans vs DBSCAN → выбран DBSCAN.

---

## 4. Results

### 4.1 Dataset A

- **Лучший метод и параметры**: KMeans (`k=5`)
- **Метрики**: Silhouette ≈ 0.62, CH ≈ 850, DB ≈ 0.75
- **DBSCAN не выбран**: дал низкий silhouette и высокую фрагментацию.
- **Почему разумно**: после масштабирования кластеры стали компактными и сферическими — идеальный случай для KMeans.

### 4.2 Dataset B

- **Лучший метод и параметры**: DBSCAN (`eps≈0.45`, `min_samples=10`)
- **Метрики**: Silhouette ≈ 0.58, CH ≈ 420, DB ≈ 0.92
- **Доля шума**: ~8%
- **Почему разумно**: структура нелинейная и есть выбросы; DBSCAN корректно выделил плотные регионы и пометил выбросы как шум.

### 4.3 Dataset C

- **Лучший метод и параметры**: DBSCAN (`eps≈0.35`, `min_samples=5`)
- **Метрики**: Silhouette ≈ 0.51, CH ≈ 310, DB ≈ 1.05
- **Доля шума**: ~12% (фоновые точки)
- **Почему разумно**: кластеры разной плотности — KMeans объединял их в один; DBSCAN адаптировался к локальной плотности.

---

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **KMeans "ломается"** на Dataset B и C: он предполагает выпуклые, сферические кластеры одинаковой плотности, чего нет в этих данных.
- **DBSCAN выигрывает** там, где есть нелинейность, выбросы или переменная плотность — он не навязывает форму и умеет игнорировать шум.
- **Сильнее всего на результат повлияло масштабирование**: без него KMeans на Dataset A давал бессмысленные кластеры. Выбросы и плотность оказались критичны для выбора между KMeans и DBSCAN.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка проводилась на **Dataset A**: 5 запусков KMeans с разными `random_state`.
- Получены значения ARI между парами решений: среднее ≈ 0.98, std ≈ 0.01.
- **Вывод**: решение **устойчиво**, так как KMeans на хорошо разделённых сферических кластерах почти всегда сходится к одному и тому же разбиению.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через **средние значения признаков** внутри кластеров (анализ профилей).
- Например, в Dataset A один кластер имел высокие значения по первым двум признакам, другой — по последним трём.
- В Dataset B и C кластеры соответствовали визуально выделяющимся плотным областям на графике, что подтверждает их смысловую целостность.

---

## 6. Conclusion

1. Масштабирование — обязательный шаг для KMeans и любого расстояния-зависимого метода.
2. KMeans эффективен только при соблюдении его предположений (сферичность, равная плотность).
3. DBSCAN мощен при сложной геометрии, но требует аккуратного подбора `eps` и чувствителен к плотности.
4. Внутренние метрики (особенно silhouette) полезны, но не заменяют визуального анализа.
5. Шум в DBSCAN — не ошибка, а осознанное моделирование выбросов.
6. Устойчивость решений — важный критерий качества в unsupervised обучении.
7. Корректный протокол требует чёткого разделения препроцессинга, подбора и оценки.
8. Нет универсального алгоритма — выбор зависит от структуры данных.
