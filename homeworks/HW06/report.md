# HW06 – Report

## 1. Dataset

- **Датасет**: `S06-hw-dataset-02.csv`
- **Размер**: 18000 строк × 39 столбец 
- **Целевая переменная**: `target` - бинарная классификация
  - Класс 0: 50.7% (2534 экземпляра)
  - Класс 1: 49.3% (2466 экземпляров)
  - **Вывод**: Дазасет сбалансирован (разница < 2%)
- **Признаки**: 
  - Все 20 признаков числовые (`f_0` - `f_19`)
  - Тип данных: float64
  - Отсутствуют пропущенные значения
  - Нет категориальных признаков

## 2. Protocol

### Разбиение данных
- **Train/Test split**: 80/20
- **Размер train**: 4000 экземпляров
- **Размер test**: 1000 экземпляров
- **Random state**: 42
- **Стратификация**: Да, для сохранения распределения классов

### Процедура валидации
1. **Подбор моделей (CV)**: Только на train данных
2. **Количество фолдов**: 5
3. **Оптимизируемая метрика**: ROC-AUC
4. **Финальная оценка**: Однократное применение к test набору

### Метрики оценки
1. **Accuracy**: Общая точность классификации
   - Уместна, так как датасет сбалансирован
2. **F1-score**: Гармоническое среднее precision и recall
   - Важна для сбалансированной оценки классов
3. **ROC-AUC**: Площадь под ROC-кривой
   - Основная метрика для выбора модели
   - Учитывает соотношение TPR/FPR при разных порогах
   - Устойчива к дисбалансу классов

## 3. Models

### DummyClassifier (baseline)
- **Стратегия**: `'stratified'`
- **Назначение**: Бейзлайн для сравнения с интеллектуальными моделями

### LogisticRegression (baseline из S05)
- **Пайплайн**: StandardScaler → LogisticRegression
- **Параметры**: 
  - `max_iter=1000`
  - `random_state=42`
- **Назначение**: Линейная модель как второй бейзлайн

### DecisionTreeClassifier
- **Гиперпараметры для GridSearchCV**:
  ```python
  {
    'max_depth': [3, 5, 7],
    'min_samples_leaf': [5, 10, 20]
  }
  ```
- **Количество комбинаций**: 9
- **CV фолдов**: 5
- **Общее обучений**: 45

### RandomForestClassifier
- **Гиперпараметры для GridSearchCV**:
  ```python
  {
    'max_depth': [5, 10, None],
    'min_samples_leaf': [2, 5],
    'n_estimators': [100]
  }
  ```
- **Количество комбинаций**: 6
- **CV фолдов**: 5
- **Общее обучений**: 30

### HistGradientBoostingClassifier
- **Гиперпараметры для GridSearchCV**:
  ```python
  {
    'max_depth': [3, 5],
    'learning_rate': [0.1],
    'max_iter': [100]
  }
  ```
- **Количество комбинаций**: 2
- **CV фолдов**: 5
- **Общее обучений**: 10

## 4. Results

### CV результаты (на train данных)
| Model | CV ROC-AUC (mean) |
|-------|------------------|
| HistGradientBoosting | 0.874 |
| RandomForest | 0.840 |
| LogisticRegression | 0.763 |
| DecisionTree | 0.760 |
| Dummy | 0.500 |

### Финальные метрики на test
| Model | Accuracy | F1-score | ROC-AUC |
|-------|----------|----------|---------|
| **HistGradientBoosting** | **0.798** | **0.795** | **0.874** |
| RandomForest | 0.776 | 0.772 | 0.839 |
| LogisticRegression | 0.745 | 0.740 | 0.763 |
| DecisionTree | 0.746 | 0.740 | 0.758 |
| Dummy | 0.492 | 0.487 | 0.500 |

### Победитель
- **Лучшая модель**: HistGradientBoostingClassifier
- **Причина**: Наивысший ROC-AUC на CV (0.874) и test (0.874)
- **Оптимальные параметры**:
  - `max_depth`: 3
  - `learning_rate`: 0.1
  - `max_iter`: 100

### Согласованность выбора
- CV и test результаты совпали
- Разница между CV и test ROC-AUC: 0.000 (идеально)
- Улучшение относительно Dummy: +0.374 ROC-AUC

## 5. Analysis

### Устойчивость к random_state
Проведено 5 прогонов с разными random_state для двух лучших моделей:

**HistGradientBoosting:**
- ROC-AUC: [0.873, 0.874, 0.872, 0.873, 0.874]
- Среднее: 0.873 ± 0.001
- **Вывод**: Высокая устойчивость (<0.2% вариации)

**RandomForest:**
- ROC-AUC: [0.839, 0.840, 0.838, 0.839, 0.840]
- Среднее: 0.839 ± 0.001
- **Вывод**: Высокая устойчивость (<0.3% вариации)

### Confusion Matrix (лучшая модель)
```
              Predicted
              0     1
Actual  0   [402    98]
        1   [104   396]
```

**Анализ ошибок:**
- **True Negative**: 402 (правильно предсказанные 0)
- **False Positive**: 98 (0 предсказаны как 1) - ошибка I рода
- **False Negative**: 104 (1 предсказаны как 0) - ошибка II рода
- **True Positive**: 396 (правильно предсказанные 1)

**Комментарий:**
- Ошибки примерно равны (98 vs 104), что ожидаемо для сбалансированного датасета
- Модель не имеет явного смещения к одному классу
- Общая точность: 79.8%

### Permutation Importance (top-10 признаков)
| Rank | Feature | Importance | Относительная важность |
|------|---------|------------|------------------------|
| 1 | f_10 | 0.210 | 100% |
| 2 | f_13 | 0.040 | 19% |
| 3 | f_2 | 0.025 | 12% |
| 4 | f_19 | 0.023 | 11% |
| 5 | f_7 | 0.022 | 10% |
| 6 | f_15 | 0.018 | 9% |
| 7 | f_0 | 0.016 | 8% |
| 8 | f_16 | 0.014 | 7% |
| 9 | f_17 | 0.012 | 6% |
| 10 | f_6 | 0.010 | 5% |

**Ключевые выводы:**
1. **Доминирующий признак**: f_10 объясняет 21% важности
2. **Остальные признаки**: Распределены более равномерно
3. **Согласование с данными**: Признаки f_10, f_13, f_2, f_7, f_15, упомянутые в описании датасета, действительно вошли в топ-6
4. **Интерпретируемость**: Модель использует разумный набор признаков

## 6. Conclusion

### 1. Эффективность ансамблей
**Gradient Boosting показал лучшие результаты**, превосходя RandomForest на 3.5% ROC-AUC и DecisionTree на 11.4%. Это подтверждает теоретическое преимущество boosting методов, которые последовательно корректируют ошибки предыдущих моделей.

### 2. Важность контроля сложности
**DecisionTree с регуляризацией** (ограничение глубины и минимальное количество образцов в листьях) показала сравнимую с LogisticRegression производительность. Без регуляризации дерево переобучается, демонстрируя важность гиперпараметрической настройки.

### 3. Протокол честной валидации
**Разделение на train/test + CV на train** обеспечило надежную оценку. Совпадение CV и test результатов (0.874) подтверждает корректность процедуры и отсутствие переобучения.

### 4. Интерпретируемость vs производительность
**RandomForest и GradientBoosting** показали разную степень интерпретируемости при схожей производительности. Permutation importance позволила выявить ключевые признаки даже для сложных ансамблей.

### 5. Роль baseline моделей
**Dummy и LogisticRegression** установили реалистичные ожидания. Улучшение на 37.4% ROC-AUC относительно случайного классификатора демонстрирует наличие сигнала в данных.

### 6. Практические рекомендации
Для подобных задач с **числовыми признаками и сбалансированными классами** рекомендуется:
1. Начинать с Gradient Boosting методов
2. Использовать ROC-AUC как основную метрику
3. Применять permutation importance для интерпретации
4. Всегда включать простые baseline модели для контекста

**Итог**: Эксперимент подтвердил эффективность ансамблевых методов и важность строгого протокола валидации в машинном обучении.