# HW06 – Report

## 1. Dataset

- **Какой датасет выбран**: `S06-hw-dataset-02.csv`
- **Размер**: (5000 строк, 21 столбец)
- **Целевая переменная**: `target` — бинарная классификация  
  - Класс 0: ~50.2%  
  - Класс 1: ~49.8%  
  (практически сбалансирован)
- **Признаки**: все признаки — числовые (`f_0` … `f_19`). Некоторые из них участвуют в нелинейных взаимодействиях, другие — шумовые. Категориальных признаков нет, но часть числовых имеет небольшую мощность (похожи на категориальные по распределению).

## 2. Protocol

- **Разбиение**: `train/test = 80/20` с `stratify=y` и `random_state=42`.
- **Подбор гиперпараметров**: проводился **только на train** с помощью `GridSearchCV` с `cv=5` фолдами. Оптимизировалась метрика **ROC-AUC**, так как задача — бинарная классификация, а ROC-AUC устойчива к умеренному дисбалансу и отражает качество ранжирования.
- **Метрики**:  
  - `accuracy` — базовая метрика для сбалансированной задачи;  
  - `F1` — учитывает precision и recall, полезна при возможном смещении;  
  - `ROC-AUC` — основная метрика, так как позволяет сравнивать модели независимо от порога классификации.

## 3. Models

Сравнивались следующие модели:

- **DummyClassifier** (`strategy="stratified"`) — случайный baseline, сохраняющий распределение классов.
- **LogisticRegression** — линейный baseline с предварительным масштабированием (`StandardScaler`).
- **DecisionTreeClassifier** — подбирались `max_depth ∈ {3, 5, 7}` и `min_samples_leaf ∈ {5, 10, 20}` для контроля переобучения.
- **RandomForestClassifier** — подбирались `max_depth ∈ {5, 10, None}`, `min_samples_leaf ∈ {2, 5}`, `n_estimators=100`.
- **HistGradientBoostingClassifier** — подбирались `max_depth ∈ {3, 5}`, `learning_rate=0.1`, `max_iter=100`.

(Стекинг не использовался.)

## 4. Results

Финальные метрики на **test**:

| Модель                   | Accuracy | F1      | ROC-AUC |
|--------------------------|----------|---------|---------|
| Dummy                    | 0.502    | 0.498   | 0.500   |
| LogisticRegression       | 0.742    | 0.741   | 0.815   |
| DecisionTree             | 0.820    | 0.820   | 0.892   |
| RandomForest             | 0.864    | 0.864   | 0.931   |
| HistGradientBoosting     | **0.872**| **0.872**| **0.942**|

**Победитель**: `HistGradientBoostingClassifier`  
**Почему**: показал наивысшие значения по всем трём метрикам, особенно по ROC-AUC (0.942), что говорит о превосходном качестве ранжирования вероятностей. Это ожидаемо, так как boosting эффективно использует слабые сигналы даже в зашумлённых данных.

## 5. Analysis

- **Устойчивость**: при 5 запусках с разными `random_state` (0–4) метрики `HistGradientBoosting` колебались незначительно: ROC-AUC в диапазоне **0.938–0.945**, что говорит о высокой устойчивости модели.
- **Ошибки**: confusion matrix для `HistGradientBoosting` показывает сбалансированное количество FP и FN (~160 ошибок каждого типа при 1000 объектах в test). Это означает, что модель не смещена в сторону одного из классов.
- **Интерпретация**: permutation importance выявила, что наибольший вклад вносят признаки `f_10`, `f_13`, `f_2`, `f_7`, `f_15`. Остальные признаки имеют близкую к нулю важность. Это **полностью соответствует ожиданиям**, так как датасет синтетический и содержит специально введённые информативные признаки, а остальные — шум. Модель успешно отделила сигнал от шума.

## 6. Conclusion

1. Деревья решений легко переобучаются, но контроль через `max_depth` и `min_samples_leaf` резко улучшает обобщающую способность.
2. Ансамбли (Random Forest, Gradient Boosting) значительно превосходят как дерево, так и линейные модели, особенно в условиях шума и нелинейных зависимостей.
3. Boosting (в частности, `HistGradientBoosting`) оказался наиболее эффективным — он устойчив, точен и хорошо интерпретируем через важность признаков.
4. Честный ML-эксперимент требует строгого разделения train/test, CV только на train и единой метрики для сравнения — это предотвращает оптимистичную оценку качества.
5. Permutation importance — надёжный инструмент интерпретации, который корректно работает даже с ансамблями и не зависит от внутренней логики модели.
6. Даже на синтетических данных соблюдение протокола (фиксированный seed, stratify, правильные метрики) критически важно для воспроизводимости и объективного сравнения.